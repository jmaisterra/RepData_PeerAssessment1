str(plants)
?sample
sample(1:6, 4, replace=TRUE)
sample(1:6, 4, replace=TRUE)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips <- sample(0:1,100, replacemente=TRUE, prob=c(0.3, 0.7))
flips <- sample(0:1,100, replace=TRUE, prob=c(0.3, 0.7))
flips <- sample(c(0,1),100, replace=TRUE, prob=c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size=100, prob = 0.7)
flips2 <- rbinom(100, size=1, prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean=100, sd=25)
?rpois
rpois(5, lamda=10)
rpois(5, lambda=10)
my_pois <- replicate(100, rpois(5,10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M"))
t4 <- strptime(t3, "%B %d, %Y %H:%M")
?strptime
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$speed, y=cars$dist)
plot(x=cars$dist, y=cars$speed)
plot(x=cars$speed, y=cars$dist)
plot(x=cars$speed, y=cars$dist xlab = "Speed")
plot(x=cars$speed, y=cars$dist, xlab = "Speed")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars,main="My Plot")
plot(cars,subtit="My Plot Subtitle")
plot(cars,sub="My Plot Subtitle")
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2
)
data(mtcars)
?boxplot
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
library(datasets)
data(iris)
?iris
head(iris)
mean(iris$Sepal.length)
mean(iris$Sepal.length, rm.na = true)
class(iris.Sepal.Length)
class(iris$Sepal.Length)
?mean
mean(iris$Sepal.length, na.rm = TRUE)
mean(iris[Sepal.length],na.rm = TRUE)
iris
head(iris)
iris[Sepal.length]
iris[,Sepal.length]
mean(spli(iris,iris$Sepal.length))
mean(split(iris,iris$Sepal.length))
mean(split(iris,iris$Sepal.Length))
mean(split(iris,iris$Sepal.Length), na.rm = TRUE)
spli(iris,iris$Sepal.Length)
split(iris,iris$Sepal.Length)
?colmeans
?colmean
?colsmean
?colsmeans
?colMeans
colMeans(iris[,"Sepal.Length"], na.rm = TRUE)
vdat <- iris[,"Sepal.Length"]
vdat
mean(vdat)
apply(iris[, 1:4], 2, mean)
apply(iris, 1, mean)
rowMeans(iris[, 1:4])
colMeans(iris)
library(datasets)
data(mtcars)
?mtcars
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
vx <- with(mtcars, tapply(hp, cyl, mean))
vx
vx[8] - vx[4]
class(vx)
vv <- as.Venctor(vx)
vv <- as.Vector(vx)
vv <- as.vector(vx)
vv
v[3]-v[1]
vv[3]-vv[1]
debug(ls)
ls
iris[,"Sepal.Length"]
mean(iris[,"Sepal.Length"])
head
head(iris)
s <- split(iris,iris$Species)
q
makeCacheMatrix <- function(x = matrix()) {
cmat <- NULL     ## Init Matrix used to calculate its Inverse
minv <- NULL     ## Init Inverse of the Matrix
set <- function(y) {     ## Set the new Matrix, init x, cmat and minv
x <<- y
cmat <<- y
minv <<- NULL
}
get <- function() x                         ## Get the Matrix to compute its Inverse
setinverse <- function(inverse, x) {
minv <<- inverse                      ## Save the calculated Inverse to the cache value
cmat <<- x                            ## Save the Matrix used in the calculation to the cache value
}
getinverse <- function() minv               ## Get the Inverse valua from the cache variable
getlastmatrix <- function() cmat            ## Get the Last Matrix used to compute the Inverse
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)               ## Return the list of functions: set, get, setinverse, getinverse
}
cacheSolve <- function(x, ...) {
cmat <- x$getlastmatrix()                   ## Get the last Matrix used to compute the cahce
minv <- x$getinverse()                      ## Gets the the last cimputed Inverse from the cache variable
## If a Matrix was used before AND there is a value in the cache value of the inverse
## AND the new Matrix x is equal the one used before, return the cahce value
if( (!is.null(cmat) && (!is.null(minv)) && identical(camt, x) = TRUE) {
message("getting cached data")
return(minv)
}
vmatrixdata <- x$get()                      ## Get the Matrix data
minv <- solve(vmatrix)                      ## Calculate it`s Inverse
x$setinverse(minv, x)                       ## Save the Inverse result and the Matrix Used in the cache variables
minv                                        ## Return the Inverse result
}
cacheSolve <- function(x, ...) {
cmat <- x$getlastmatrix()                   ## Get the last Matrix used to compute the cahce
minv <- x$getinverse()                      ## Gets the the last cimputed Inverse from the cache variable
## If a Matrix was used before AND there is a value in the cache value of the inverse
## AND the new Matrix x is equal the one used before, return the cahce value
if( (!is.null(cmat) && (!is.null(minv)) && identical(camt, x) = TRUE) {
message("getting cached data")
return(minv)
}
vmatrixdata <- x$get()                      ## Get the Matrix data
minv <- solve(vmatrix)                      ## Calculate it`s Inverse
x$setinverse(minv, x)                       ## Save the Inverse result and the Matrix Used in the cache variables
minv                                        ## Return the Inverse result
}
cacheSolve <- function(x, ...) {
cmat <- x$getlastmatrix()                   ## Get the last Matrix used to compute the cahce
minv <- x$getinverse()                      ## Gets the the last cimputed Inverse from the cache variable
## If a Matrix was used before AND there is a value in the cache value of the inverse
## AND the new Matrix x is equal the one used before, return the cahce value
if( (!is.null(cmat)) && (!is.null(minv)) && identical(camt, x) = TRUE) {
message("getting cached data")
return(minv)
}
vmatrixdata <- x$get()                      ## Get the Matrix data
minv <- solve(vmatrix)                      ## Calculate it`s Inverse
x$setinverse(minv, x)                       ## Save the Inverse result and the Matrix Used in the cache variables
minv                                        ## Return the Inverse result
}
cacheSolve <- function(x, ...) {
cmat <- x$getlastmatrix()                   ## Get the last Matrix used to compute the cahce
minv <- x$getinverse()                      ## Gets the the last cimputed Inverse from the cache variable
## If a Matrix was used before AND there is a value in the cache value of the inverse
## AND the new Matrix x is equal the one used before, return the cahce value
if( (!is.null(cmat)) && (!is.null(minv)) && identical(camt, x) = TRUE) {
message("getting cached data")
return(minv)
}
vmatrixdata <- x$get()                      ## Get the Matrix data
minv <- solve(vmatrix)                      ## Calculate it`s Inverse
x$setinverse(minv, x)                       ## Save the Inverse result and the Matrix Used in the cache variables
minv                                        ## Return the Inverse result
}
cacheSolve <- function(x, ...) {
cmat <- x$getlastmatrix()                   ## Get the last Matrix used to compute the cahce
minv <- x$getinverse()                      ## Gets the the last cimputed Inverse from the cache variable
## If a Matrix was used before AND there is a value in the cache value of the inverse
## AND the new Matrix x is equal the one used before, return the cahce value
if( (!is.null(cmat)) && (!is.null(minv)) && identical(camt, x) == TRUE) {
message("getting cached data")
return(minv)
}
vmatrixdata <- x$get()                      ## Get the Matrix data
minv <- solve(vmatrix)                      ## Calculate it`s Inverse
x$setinverse(minv, x)                       ## Save the Inverse result and the Matrix Used in the cache variables
minv                                        ## Return the Inverse result
}
install.packages("RMySQL")
install.packages("RMySQL")
test1 <- dbConnect(MySQL,user="root",host="localhost")
dbconnect
dbConnect
? dbConnect
test1 <- dbConnect(Mysql(),user="root",host="localhost")
test1 <- dbConnect()
library("RMySQL", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
test1 <- dbConnect(Mysql(),user="root",host="localhost")
? dbConnect
test1 <- dbConnect(Mysql(),user="root",host="localhost")
test1 <- dbConnect(Mysql(),User="root",Host="localhost")
install.packages("dbConnect")
library("dbConnect", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
test1 <- dbConnect(Mysql(),user="root",host="localhost")
test1 <- dbConnect(Mysql(),User="root",Host="localhost")
install.packages("swirl")
R.version.string
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package,
| country)
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, county:r_arch)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -5:20)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "IN" | country == "US")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
?n
?n_distinct
count = n()
pack_sum <- summarize(by_package,
count = ,
unique = ,
countries = ,
avg_bytes = )
unique = n_distinct(ip_id)
pack_sum <- summarize(by_package,count = n())
pack_sum
pack_sum <- summarize(by_package,count = n(), unique = n_distinct())
pack_sum <- summarize(by_package,count = n(), unique = n_distinct(ip_id))
pack_sum <- summarize(by_package,count = n(), unique = n_distinct(ip_id), countries = n_distinct(country), avg_bytes = mean(size))
pack_sum
submit()
pack_sum <- summarize(by_package,count = n(), unique = n_distinct(ip_id), countries = n_distinct(country), avg_bytes = mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count))
View(top_counts)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum,unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
submit()
View(resilt3)
View(result3)
cran %>% select(ip_id,country,package,size) %>% print
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2,sex_class,count,-grade)
res
?separate
separate(res,sex_class,into= c("sex","class"))
submit()
students3
gater(students3,class,grade,-name)
gather(students3,class,grade,-name)
?gather
submit()
?spread()
?spread
submit()
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, c("midterm","final")) %>%
print
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, grade %>%
print
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, grade) %>%
print
submit()
extract_numeric("class5").
extract_numeric("class5")
submit()
students4
submit()
submit()
?unique
submit()
submit()
passed
failed
passed <- mutate(passed,status = "passed")
failed <- mutate(failed,status="failed")
?bind_rows
?bind_rows
bind_rows(passed,failed)
sat
?separate
submit()
select(sat,-contains(total))
select(sat,-contains("total"))
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <_ today()
this_day <- today()
this_day
month(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989
| May 17")
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920_1_2")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = hours(now()), minutes = minutes(now()), seconds = seconds(now()))
this_moment <- update(this_moment, hours = hour(now()), minutes = minute(now()), seconds = seconds(now()))
this_moment
?now
myc <- now(tzone="America/New_York")
myc <- now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc+days(2)
depart
depart <- update(depart,hour = hour(depart)+hours(17), minute = minute(depart)+minutes(34))
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive,"Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008","Asia/Singapore")
last_time <- mdy("June 17, 2008",tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "a72ed961a341585a9dab",
secret = "6b68237a21474bc214d9da01d9ef500a8d111531")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "56b637a5baffac62cad9",
secret = "8e107541ae1791259e9987d544ca568633da2ebf")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
swirl()
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:ggplot2", unload=TRUE)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
remove.packages("ggplot2")
swirl()
swirl
swirl()
library(swirl)
swirl()
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("ggplot2")
library("ggplot2")
r.version()
sessionInfo()
version
version
update.packages(checkBuilt=TRUE)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("ggplot2")
library(ggplot2)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
swirl()
install.packages("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
library(swirl)
swirl()
setwd("~/Desktop/COURSERA DATA SCIENCE SPECIALIIZATION/5) Reproducible Research/RepData_PeerAssessment1")
unzip("activity.zip")
data <- read.csv("activity.csv", colClasses = c("integer", "Date", "factor"))
data$month <- as.numeric(format(data$date, "%m"))
noNA <- na.omit(data)
rownames(noNA) <- 1:nrow(noNA)
head(noNA)
dim(noNA)
library(ggplot2)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
system("ls -ld /usr/local /usr/local/lib /usr/local/lib/libtcl*")
detach("package:ggplot2", unload=TRUE)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
